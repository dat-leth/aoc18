{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d1_read_input(input_path):\n",
    "    with open(input_path, 'r') as f:\n",
    "        list = [int(line) for line in f]\n",
    "        return list\n",
    "\n",
    "\n",
    "def d1_1_resulting_frequency(change_sequence):\n",
    "    return sum(change_sequence)\n",
    "\n",
    "\n",
    "d1_1_resulting_frequency(d1_read_input('./input1.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d1_2_resulting_frequency(change_sequence):\n",
    "    res_freq_set = set()\n",
    "    cycle_seq = cycle(change_sequence)\n",
    "    result = 0\n",
    "    \n",
    "    for change in cycle_seq:\n",
    "        result = result + change\n",
    "        if result not in res_freq_set:\n",
    "            res_freq_set.add(result)\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "\n",
    "d1_2_resulting_frequency(d1_read_input('./input1.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2_read_input(input_path):\n",
    "    with open(input_path, 'r') as f:\n",
    "        list = [line for line in f]\n",
    "        return list\n",
    "\n",
    "def d2_1_checksum(id_list):\n",
    "    count2 = 0\n",
    "    count3 = 0\n",
    "    for id in id_list:\n",
    "        seen2 = set([char for char in id if id.count(char) == 2])\n",
    "        seen3 = set([char for char in id if id.count(char) == 3])\n",
    "        \n",
    "        if len(seen2) != 0: \n",
    "            count2 += 1\n",
    "            \n",
    "        if len(seen3) != 0:\n",
    "            count3 += 1\n",
    "            \n",
    "    return count2 * count3\n",
    "\n",
    "d2_1_checksum(d2_read_input('./input2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2_2_common_letters(id_list):\n",
    "    for id1 in id_list:\n",
    "        for id2 in id_list:\n",
    "            if id1 != id2:\n",
    "                not_matching_letters = [char1 for char1, char2 in zip(id1, id2) if char1 != char2]\n",
    "                if len(not_matching_letters) == 1:\n",
    "                    print(id1, id2)\n",
    "                    return(id1.replace(not_matching_letters[0], ''))\n",
    "\n",
    "\n",
    "d2_2_common_letters(d2_read_input('./input2.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def d3_read_input(input_path):\n",
    "    list = []\n",
    "    with open(input_path, 'r') as f:\n",
    "        for line in f:\n",
    "            split = line.split()\n",
    "            claim_id = split[0]\n",
    "            left, top = split[2].replace(':', '').split(',')\n",
    "            width, height = split[3].split('x')\n",
    "            list.append((claim_id, int(left), int(top), int(width), int(height)))\n",
    "    return list\n",
    "            \n",
    "def d3_1_area_of_intersection(claims):\n",
    "    grid = np.zeros(shape=(1000, 1000), dtype=np.int32)\n",
    "    \n",
    "    for claim in claims:\n",
    "        grid[claim[1]:claim[1]+claim[3], claim[2]:claim[2]+claim[4]] += 1\n",
    "    \n",
    "    print(np.sum(grid >= 2))\n",
    "    \n",
    "    #part 2\n",
    "    for claim in claims:\n",
    "        if np.all(grid[claim[1]:claim[1]+claim[3], claim[2]:claim[2]+claim[4]] == 1):\n",
    "            return claim\n",
    "    \n",
    "d3_1_area_of_intersection(d3_read_input('./input3.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import collections\n",
    "\n",
    "def parse_timestamp(d, t):\n",
    "    return datetime.datetime.strptime('{} {}'.format(d, t), \"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# parse records\n",
    "def d4_1():\n",
    "    guard_dict = collections.defaultdict(int)\n",
    "    guard_min_dict = collections.defaultdict(list)\n",
    "    minute_dict = collections.defaultdict(list)\n",
    "    with open('./input4.txt', 'r') as f:\n",
    "        guard_id = 0\n",
    "        sorted_f = sorted(f)\n",
    "        for i, line in enumerate(sorted_f):\n",
    "            words = line.split()\n",
    "            if '#' in line:\n",
    "                guard_id = int(words[3][1:])\n",
    "            if 'wakes' in line:\n",
    "                timestamp_wakeup = parse_timestamp(words[0][1:], words[1][:-1])\n",
    "                previous_line = sorted_f[i - 1]\n",
    "                previous_words = previous_line.split()\n",
    "                timestamp_asleep = parse_timestamp(previous_words[0][1:], previous_words[1][:-1])\n",
    "                sleep_duration = (timestamp_wakeup - timestamp_asleep).total_seconds() // 60\n",
    "                guard_dict[guard_id] += sleep_duration\n",
    "                \n",
    "                asleep_minute = int(previous_words[1][:-1].split(':')[1])\n",
    "                wakeup_minute = int(words[1][:-1].split(':')[1])\n",
    "                for minute in range(asleep_minute, wakeup_minute):\n",
    "                    guard_min_dict[guard_id].append(minute)\n",
    "                    minute_dict[minute].append(guard_id)\n",
    "    \n",
    "    max_id = max(guard_dict, key=guard_dict.get)\n",
    "    most_occuring_minute_of_max_id = collections.Counter(guard_min_dict[max_id]).most_common(1)[0][0]\n",
    "    print(max_id, most_occuring_minute_of_max_id, max_id * most_occuring_minute_of_max_id)\n",
    "\n",
    "    # part 2\n",
    "    guard = value = count = 0\n",
    "    for g in guard_min_dict:\n",
    "        v, c = collections.Counter(guard_min_dict[g]).most_common(1)[0]\n",
    "        if count < c:\n",
    "            count = c\n",
    "            value = v\n",
    "            guard = g\n",
    "            \n",
    "    print(guard, value, guard * value)\n",
    "    \n",
    "d4_1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
